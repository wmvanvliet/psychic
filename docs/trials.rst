.. _trials:

Managing trials
===============

A trial is a segment of EEG data related to a specific event. These events could
be the presentation of a stimulus on the screen, the onset of a button press,
etc. When analyzing such EEG recordings, its useful to cut out segments around
the onset of the events. Later, these segments can for example be averaged to
study event-related potentials, or these segments could be used as input for a
classifier to construct a brain-computer interface.

Slicing
-------

To extract trials from a continuous recording, the :class:`psychic.nodes.Slice`
node can be used. It assumes that the recording provides a marker stream: a
channel which contains numerical codes indicating the type of event occuring.
The signal starts at 0. At the onset of an event, the signal jumps to a value
which corresponds to the type of event and remains there for the duration of the
event. After the event, the signal either returns to 0 or jumps to a different
value, indicating the onset of a different event.

.. figure::  images/marker_stream.png
   :align:   center

   Graphical representation of an example marker stream

Usually the marker stream is generated by the EEG amplifier. To synchronize the
presentation of stimuli with the EEG, a physical cable connects the presentation
computer and one of the inputs of the EEG amplifier. This effectively creates a
new channel, sometimes called the STATUS or STIM channel. Whenever a stimulus is
shown on the screen, the presentation computer sends a pulse through the cable,
resulting in a marker stream like the one presented in the figure.

To extract trials by slicing segments starting 200 ms before the onset of the
event lasting to 1 second after:

>>> import psychic
>>> import numpy
>>> d = psychic.load_bdf(psychic.find_data_path('priming-short.bdf'))
>>> mdict = {1:'event type 1', 2:'event_type 2'}
>>> slicer = psychic.nodes.Slice(mdict, (-0.2, 1.0))
>>> trials = slicer.train_apply(d)
>>> print trials
DataSet with 208 instances, 12280 features [40x307], 2 classes: [104, 104], extras: []

Using a sliding window
----------------------

Another commonly used approach to obtain trials is to apply a sliding window.

.. figure::  images/sliding_window.png
   :align:   center

   Sliding window with size 2 and step 1.3 (seconds). 

This operation can be performed with the :class:`psychic.nodes.SlidingWindow`
node. The example below extracts trials using a sliding window of 2 seconds that
is moved across the signal in steps of 1.3 seconds:

>>> import psychic
>>> d = psychic.fake.gaussian(nchannels=4, duration=10, sample_rate=100)
>>> window = psychic.nodes.SlidingWindow(win_size=2, win_step=1.3)
>>> trials = window.train_apply(d)
>>> print trials
DataSet with 7 instances, 800 features [4x200], 1 classes: [7], extras: []

.. _baseline:

Baselining trials
-----------------

Due to drifts in the EEG signal, the mean signal of a trial is not always
aligned to zero. Especially during ERP analysis, it's important to align the
trials to some meaningful 'baseline' voltage in order to compare them. The
:class:`psychic.nodes.Baseline` node calculates a baseline and aligns the signal
accordingly.

.. figure::  images/baseline.png
   :align:   center

   When comparing ERPs of two classes, it's important to align both ERPs properly.
   In this case, the baseline is calculated from -0.2 seconds to the onset of
   the stimulus.

An example usage of the :class:`psychic.nodes.Baseline` node:

>>> d = psychic.load_bdf(psychic.find_data_path('priming-short.bdf'))
>>> mdict = {1:'event type 1', 2:'event_type 2'}
>>> slicer = psychic.nodes.Slice(mdict, (-0.2, 1.0))
>>> trials = slicer.train_apply(d)
>>> baseliner = psychic.nodes.Baseline((-0.2, 0))
>>> trials_baselined = baseliner.train_apply(trials)
>>> print trials_baselined
DataSet with 208 instances, 12280 features [40x307], 2 classes: [104, 104], extras: []

Constructing ERPs
-----------------

By averaging trials, the Event-Related Potentials (ERPs) can be studied. The theory is
that by averaging, any activity that is similar across trials remains, while any activity
that differs between trials cancels out.

Before doing such analysis, it's important that the ERPs will be lined up correctly. Which
means frequency filtering (:ref:`frequency filter`) and baselining (:ref:`baseline`) the data
first.

The :class:`psychic.nodes.ERP` node constructs an ERP by averaging the trials
belonging to each class. The result is a dataset with the ERPs:

 - ``d.ndX``: [channels x samples x classes] The ERP data 
 - ``d.Y``: [classes x classes] Identity matrix mapping one ERP to each class
 - ``d.cl_lab``: The class labels

>>> import golem
>>> trials = golem.DataSet.load(psychic.find_data_path('priming-trials.dat'))
>>> trials = psychic.nodes.Butterworth(4, (0.01, 30)).train_apply(trials)
>>> trials = psychic.nodes.Baseline((-0.7, -0.5)).train_apply(trials)
>>> erp = psychic.nodes.ERP().train_apply(trials)
>>> print erp
DataSet with 2 instances, 17400 features [40x435], 2 classes: [1, 1], extras: []
